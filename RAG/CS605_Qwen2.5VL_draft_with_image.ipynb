{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "564aab1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nThis is the notebook for running Qwen 2.5 VL locally \\nby howchih.lee.2024@mitb.smu.edu.sg\\n\\nAgentic RAG with PDF upload of mixed modality for conversion to text vectors\\n\\nOperating in venv with Python 3.11.9\\n\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "This is the notebook for running Qwen 2.5 VL locally \n",
    "by howchih.lee.2024@mitb.smu.edu.sg\n",
    "\n",
    "Agentic RAG with PDF upload of mixed modality for conversion to text vectors\n",
    "\n",
    "Operating in venv with Python 3.11.9\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b87c24f",
   "metadata": {},
   "source": [
    "## Part 1: Load Dependencies and Verify Environment properly created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "49c95b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Verify that nomic_emebed_text:latest and qwen2.5vl:3b are installed locally under .ollama directory, otherwise follow instructions on README.md to download to environment in Terminal before proceeding.\n",
    "\n",
    "#!ollama list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "59bcc213",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load Dependencies from requirements.txt\n",
    "#!pip install -r requirements.txt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bfb482e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# When running transformers, if you encountered error on \"Replicate\", your transformer version is not up to date.  \n",
    "# Install latest transformers from source on hugging face using this cell, then Restart and run from the top. \n",
    "# Takes over 40s to run, so please be patient.\n",
    "# After Restart, do not run this cell again. \n",
    "\n",
    "#!pip install git+https://github.com/huggingface/transformers --upgrade --quiet\n",
    "\n",
    "#print(\"‚úÖ Transformers updated from source\")\n",
    "#print(\"üîÑ Please restart your kernel after this completes\")\n",
    "#print(\"Then re-run the model loading cells except for this cell\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c50d2966",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Config loaded - Base directory: C:\\Users\\pakke\\OneDrive - Singapore Management University\\CS605 Natural Language Processing for Smart Assistant\\Project\\RAG\n",
      "‚úÖ Data directory: C:\\Users\\pakke\\OneDrive - Singapore Management University\\CS605 Natural Language Processing for Smart Assistant\\Project\\RAG\\data\n",
      "‚úÖ Cache directory: C:\\Users\\pakke\\OneDrive - Singapore Management University\\CS605 Natural Language Processing for Smart Assistant\\Project\\RAG\\cache\n",
      "‚úÖ Language dictionaries: C:\\Users\\pakke\\OneDrive - Singapore Management University\\CS605 Natural Language Processing for Smart Assistant\\Project\\RAG\\cache\\lang_dict\n",
      "PyTorch version: 2.7.0+cu126\n",
      "CUDA available: True\n",
      "CUDA version: 12.6\n",
      "GPU device: NVIDIA RTX 2000 Ada Generation Laptop GPU\n",
      "Transformers version: 4.52.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Successfully loaded a test model\n",
      "\n",
      "Environment setup completed.\n"
     ]
    }
   ],
   "source": [
    "## Test environment\n",
    "import torch\n",
    "import transformers\n",
    "from transformers import AutoModelForCausalLM, AutoProcessor\n",
    "import gc\n",
    "import os\n",
    "import psutil\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from config import *\n",
    "\n",
    "def check_environment():\n",
    "    # Check PyTorch and CUDA\n",
    "    print(f\"PyTorch version: {torch.__version__}\")\n",
    "    print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "    if torch.cuda.is_available():\n",
    "        print(f\"CUDA version: {torch.version.cuda}\")\n",
    "        print(f\"GPU device: {torch.cuda.get_device_name(0)}\")\n",
    "    \n",
    "    # Check Transformers\n",
    "    print(f\"Transformers version: {transformers.__version__}\")\n",
    "    \n",
    "    # Check if we can load a small model (not Qwen yet)\n",
    "    try:\n",
    "        processor = AutoProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "        print(\"‚úÖ Successfully loaded a test model\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error loading test model: {e}\")\n",
    "    \n",
    "    print(\"\\nEnvironment setup completed.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    check_environment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "40b98969",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Memory management and CPU optimization\n",
    "\n",
    "def setup_cpu_optimization():\n",
    "    \"\"\"Optimize PyTorch for CPU-only inference\"\"\"\n",
    "    \n",
    "    # Set thread count for optimal CPU performance\n",
    "    torch.set_num_threads(4)  # Adjust based on your CPU\n",
    "    \n",
    "    # Optimize for inference\n",
    "    torch.set_grad_enabled(False)\n",
    "    \n",
    "    # Set memory allocation strategy\n",
    "    torch.backends.quantized.engine = 'fbgemm'\n",
    "    \n",
    "    print(f\"‚úÖ CPU optimization configured\")\n",
    "    print(f\"   Threads: {torch.get_num_threads()}\")\n",
    "    print(f\"   Grad enabled: {torch.is_grad_enabled()}\")\n",
    "\n",
    "def clear_memory():\n",
    "    \"\"\"Clear memory cache\"\"\"\n",
    "    gc.collect()\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "    print(\"üßπ Memory cleared\")\n",
    "\n",
    "def check_memory_usage():\n",
    "    \"\"\"Check current memory usage\"\"\"\n",
    "    process = psutil.Process(os.getpid())\n",
    "    memory_info = process.memory_info()\n",
    "    memory_mb = memory_info.rss / 1024 / 1024\n",
    "    \n",
    "    print(f\"üìä Memory Usage: {memory_mb:.1f} MB\")\n",
    "    return memory_mb\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1d98a3f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ CPU optimization configured\n",
      "   Threads: 4\n",
      "   Grad enabled: False\n",
      "üßπ Memory cleared\n",
      "üìä Memory Usage: 951.5 MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "951.4609375"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setup CPU optimization\n",
    "## The Qwuen2.5vl:3b model should take up 340MB of memory. \n",
    "setup_cpu_optimization()\n",
    "clear_memory()\n",
    "check_memory_usage()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5fae550",
   "metadata": {},
   "source": [
    "## Part 2: Using ollama, load \"qwen2.5vl:3b\" from ollama list. Verify that it works with sample prompt. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2900f673",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:src.document_processor:OCR not available - install pytesseract for image-based text extraction\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Imports successful\n"
     ]
    }
   ],
   "source": [
    "# Import the model manager and necessary dependencies\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add project root to path if needed\n",
    "project_root = Path.cwd()\n",
    "sys.path.insert(0, str(project_root))\n",
    "\n",
    "# Import our model manager classes\n",
    "from src.model_manager import OllamaManager, QwenMultimodalManager\n",
    "from src.document_processor import DocumentProcessor\n",
    "from config import *\n",
    "\n",
    "import torch\n",
    "import os\n",
    "import logging\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import io\n",
    "\n",
    "# Setup logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Memory management - reuse your existing functions\n",
    "def clear_memory():\n",
    "    \"\"\"Clear memory cache\"\"\"\n",
    "    import gc\n",
    "    gc.collect()\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "    print(\"üßπ Memory cleared\")\n",
    "\n",
    "print(\"‚úÖ Imports successful\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "060e842b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:src.model_manager:OllamaManager initialized with model: qwen2.5vl:3b\n",
      "INFO:src.model_manager:Model qwen2.5vl:3b is available locally\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Model available: True\n",
      "\n",
      "üîç Testing simple text generation with model: qwen2.5vl:3b\n",
      "‚úÖ Generation successful!\n",
      "Response: 1. Singapore Zoo\n",
      "2. Singapore Botanic Gardens\n",
      "3. Singapore River\n",
      "4. Singapore Flyer\n",
      "5. Sentosa Island\n",
      "Duration: 3.49 seconds\n"
     ]
    }
   ],
   "source": [
    "# Update the OllamaManager with the correct model name\n",
    "ollama_manager = OllamaManager(model_name=\"qwen2.5vl:3b\")\n",
    "\n",
    "# Check if model is available\n",
    "model_available = ollama_manager.check_model_available()\n",
    "print(f\"‚úÖ Model available: {model_available}\")\n",
    "\n",
    "if not model_available:\n",
    "    print(\"‚ö†Ô∏è Model not available. Pulling now (this may take a while)...\")\n",
    "    model_pulled = ollama_manager.pull_model()\n",
    "    print(f\"‚úÖ Model pulled: {model_pulled}\")\n",
    "\n",
    "# Test simple text generation with the updated model name\n",
    "print(\"\\nüîç Testing simple text generation with model: qwen2.5vl:3b\")\n",
    "response = ollama_manager.generate_text(\n",
    "    \"What are the top 5 tourist attractions in Singapore?\",\n",
    "    max_tokens=100\n",
    ")\n",
    "\n",
    "if 'error' in response:\n",
    "    print(f\"‚ùå Generation failed: {response['error']}\")\n",
    "    \n",
    "    # Try the quantized version if standard version fails\n",
    "    print(\"\\nüîç Trying quantized version: qwen2.5vl:3b-q4_K_M\")\n",
    "    ollama_manager = OllamaManager(model_name=\"qwen2.5vl:3b-q4_K_M\")\n",
    "    \n",
    "    model_available = ollama_manager.check_model_available()\n",
    "    if not model_available:\n",
    "        print(\"‚ö†Ô∏è Quantized model not available. Pulling now...\")\n",
    "        ollama_manager.pull_model()\n",
    "    \n",
    "    response = ollama_manager.generate_text(\n",
    "        \"What are the top 5 tourist attractions in Singapore?\",\n",
    "        max_tokens=150\n",
    "    )\n",
    "    \n",
    "    if 'error' in response:\n",
    "        print(f\"‚ùå Generation with quantized model failed: {response['error']}\")\n",
    "    else:\n",
    "        print(f\"‚úÖ Generation with quantized model successful!\")\n",
    "        print(f\"Response: {response['response']}\")\n",
    "else:\n",
    "    print(f\"‚úÖ Generation successful!\")\n",
    "    print(f\"Response: {response['response']}\")\n",
    "    print(f\"Duration: {response['total_duration'] / 1e9:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dda5ca7f",
   "metadata": {},
   "source": [
    "## Part 3: Create Document Processing Pipeline for PDFs with images, diagrams, tables and save to specific drive for this project. \n",
    "## Create vector embeddings for text and images from processed PDFs.Takes more than 30 mins using 3b model for singapore_explorer_guide.pdf\n",
    "\n",
    "\n",
    "## Note: tests.py tests whether src in library are working, but does not save the output to any specific drive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e7595be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import our custom RAG components\n",
    "from src.embedding_manager import EmbeddingManager\n",
    "from src.chroma_manager import ChromaManager\n",
    "from src.rag_manager import RAGManager\n",
    "from src.document_processor import DocumentProcessor\n",
    "from datetime import datetime\n",
    "\n",
    "# Additional imports for visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import pandas as pd\n",
    "from IPython.display import display, HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4fbaa7cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:src.embedding_manager:EmbeddingManager initialized with text model: nomic-embed-text, vision model: qwen2.5vl:3b\n",
      "INFO:src.chroma_manager:Using existing collection: sg_explorer_documents\n",
      "INFO:src.chroma_manager:ChromaManager initialized with collection: sg_explorer_documents\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Components initialized\n",
      "   - Using text embedding model: nomic-embed-text\n",
      "   - Using vision model: qwen2.5vl:3b\n",
      "   - ChromaDB persistence directory: C:\\Users\\pakke\\OneDrive - Singapore Management University\\CS605 Natural Language Processing for Smart Assistant\\Project\\RAG\\cache\\vector_db\n"
     ]
    }
   ],
   "source": [
    "# Initialize our embedding manager with the models we verified are working\n",
    "embedding_manager = EmbeddingManager(\n",
    "    text_embedding_model=\"nomic-embed-text\",  # Specialized embedding model\n",
    "    vision_model=\"qwen2.5vl:3b\"               # Vision model for image descriptions\n",
    ")\n",
    "\n",
    "# Initialize ChromaDB manager\n",
    "chroma_manager = ChromaManager(\n",
    "    persist_directory=VECTOR_DB_PATH,          # From config.py\n",
    "    embedding_model=\"nomic-embed-text\",        # Should match embedding_manager\n",
    "    collection_name=\"sg_explorer_documents\"         # Collection name for this project\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ Components initialized\")\n",
    "print(f\"   - Using text embedding model: nomic-embed-text\")\n",
    "print(f\"   - Using vision model: qwen2.5vl:3b\")\n",
    "print(f\"   - ChromaDB persistence directory: {VECTOR_DB_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3553938",
   "metadata": {},
   "source": [
    "### Part 3a: Use this section for processing pdf that have text or images flattened into pdf. Eg. tourist brochures, print material where text and images cannot be easily extracted. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5ae032b3-00ff-4533-bcc9-0a17160b8c60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pakke\\anaconda3\\envs\\nlp\\Lib\\site-packages\\fitz\\__init__.py\n"
     ]
    }
   ],
   "source": [
    "import fitz\n",
    "print(fitz.__file__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2eabed74",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:src.document_processor:DocumentProcessor initialized with config: {'max_image_size': 1024, 'chunk_size': 1024, 'chunk_overlap': 128, 'data_dir': WindowsPath('C:/Users/pakke/OneDrive - Singapore Management University/CS605 Natural Language Processing for Smart Assistant/Project/RAG/data'), 'cache_dir': WindowsPath('C:/Users/pakke/OneDrive - Singapore Management University/CS605 Natural Language Processing for Smart Assistant/Project/RAG/cache')}\n",
      "INFO:src.document_processor:Processing mixed PDF: text=singapore_explorer_guide_text1.pdf, image=singapore_explorer_guide_image1.pdf\n",
      "INFO:src.document_processor:Processing text-only PDF...\n",
      "INFO:src.document_processor:Processing singapore_explorer_guide_text1.pdf (format: pdf, size: 32595939 bytes)\n",
      "INFO:src.document_processor:Processing PDF singapore_explorer_guide_text1.pdf with 10 pages\n",
      "WARNING:src.document_processor:No text found on page 1 with any method (including OCR)\n",
      "WARNING:src.document_processor:No text found on page 2 with any method (including OCR)\n",
      "WARNING:src.document_processor:No text found on page 3 with any method (including OCR)\n",
      "WARNING:src.document_processor:No text found on page 4 with any method (including OCR)\n",
      "WARNING:src.document_processor:No text found on page 5 with any method (including OCR)\n",
      "WARNING:src.document_processor:No text found on page 6 with any method (including OCR)\n",
      "WARNING:src.document_processor:No text found on page 7 with any method (including OCR)\n",
      "WARNING:src.document_processor:No text found on page 8 with any method (including OCR)\n",
      "WARNING:src.document_processor:No text found on page 9 with any method (including OCR)\n",
      "WARNING:src.document_processor:No text found on page 10 with any method (including OCR)\n",
      "INFO:src.document_processor:PDF processing complete: 0 content pieces extracted\n",
      "INFO:src.document_processor:Successfully processed singapore_explorer_guide_text1.pdf: 0 content pieces extracted, type: unknown (confidence: 0.000)\n",
      "INFO:src.document_processor:Processing image-only PDF...\n",
      "INFO:src.document_processor:Converting 10 PDF pages to images: singapore_explorer_guide_image1.pdf\n",
      "INFO:src.document_processor:PDF page conversion complete: 10 page images extracted\n",
      "INFO:src.document_processor:Generated coordinate mapping for 10 pages\n",
      "INFO:src.document_processor:  - Created 0 content relationships\n",
      "INFO:src.document_processor:Mixed PDF processing complete: 10 total content pieces\n",
      "INFO:src.document_processor:  - Text items: 0\n",
      "INFO:src.document_processor:  - Image items: 10\n"
     ]
    }
   ],
   "source": [
    "# Process mixed PDF of text and flattened images, takes more than 1 min\n",
    "import fitz\n",
    "from datetime import datetime\n",
    "\n",
    "document_processor = DocumentProcessor()\n",
    "\n",
    "mixed_doc = document_processor.process_mixed_pdf(\n",
    "    text_pdf_path=str(DATA_DIR / \"singapore_explorer_guide_text1.pdf\"),\n",
    "    image_pdf_path=str(DATA_DIR / \"singapore_explorer_guide_image1.pdf\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6fa1f0ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store contents from pre-processing\n",
    "text_contents = [c for c in mixed_doc.extracted_contents if c.content_type.value == 'text']\n",
    "image_contents = [c for c in mixed_doc.extracted_contents if c.content_type.value == 'image']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b210ab5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîÑ Processing text content...\n",
      "\n",
      "üîÑ Processing image content...\n",
      "\n",
      "üìä Embedding generation summary:\n",
      "  - Text items: 0, successfully embedded: 0\n",
      "  - Image items: 0, successfully embedded: 0\n"
     ]
    }
   ],
   "source": [
    "# Create vector embeddings, one for text, one for images, one for linking the two, for each PDF\n",
    "\n",
    "## Takes more than 25 mins to run\n",
    "## The embeddings are stored in a temp file, different for each PDF. \n",
    "## The results will be saved in the ChromaDB vector database.\n",
    "\n",
    "## Skip this cell if you want to query a PDF that has already been processed and stored in the vector database.\n",
    "\n",
    "text_embeddings = []\n",
    "text_ids = []\n",
    "text_documents = []\n",
    "text_metadatas = []\n",
    "\n",
    "# Process text content\n",
    "print(\"\\nüîÑ Processing text content...\")\n",
    "for i, content in enumerate(text_contents):\n",
    "    print(f\"  Processing text item {i+1}/{len(text_contents)}: {content.content_id}\")\n",
    "    text = content.content_data\n",
    "    content_id = content.content_id\n",
    "    \n",
    "    # Generate embedding\n",
    "    embedding = embedding_manager.generate_text_embedding(text)\n",
    "    \n",
    "    if embedding:\n",
    "        text_embeddings.append(embedding)\n",
    "        text_ids.append(content_id)\n",
    "        text_documents.append(text)\n",
    "        text_metadatas.append({\n",
    "            \"source\": mixed_doc.filename,\n",
    "            \"page\": content.source_page,\n",
    "            \"content_type\": \"text\",\n",
    "            \"document_type\": mixed_doc.document_type.value\n",
    "        })\n",
    "        print(f\"  ‚úÖ Generated embedding for {content_id}\")\n",
    "    else:\n",
    "        print(f\"  ‚ùå Failed to generate embedding for {content_id}\")\n",
    "\n",
    "# Process image content\n",
    "print(\"\\nüîÑ Processing image content...\")\n",
    "image_embeddings = []\n",
    "image_ids = []\n",
    "image_documents = []\n",
    "image_metadatas = []\n",
    "\n",
    "import tempfile\n",
    "import os\n",
    "\n",
    "for i, content in enumerate(image_contents):\n",
    "    print(f\"  Processing image item {i+1}/{len(image_contents)}: {content.content_id}\")\n",
    "    # Save image to temp file\n",
    "    image = content.content_data\n",
    "    content_id = content.content_id\n",
    "    \n",
    "    with tempfile.NamedTemporaryFile(suffix=\".png\", delete=False) as temp_file:\n",
    "        temp_path = temp_file.name\n",
    "        image.save(temp_path)\n",
    "    \n",
    "    try:\n",
    "        # Generate description\n",
    "        description = embedding_manager.generate_image_description(temp_path)\n",
    "        \n",
    "        if description:\n",
    "            print(f\"  ‚úì Generated description ({len(description)} chars)\")\n",
    "            \n",
    "            # Generate embedding for description\n",
    "            embedding = embedding_manager.generate_text_embedding(description)\n",
    "            \n",
    "            if embedding:\n",
    "                image_embeddings.append(embedding)\n",
    "                image_ids.append(content_id)\n",
    "                image_documents.append(description)\n",
    "                image_metadatas.append({\n",
    "                    \"source\": mixed_doc.filename,\n",
    "                    \"page\": content.source_page,\n",
    "                    \"content_type\": \"image_description\",\n",
    "                    \"document_type\": mixed_doc.document_type.value\n",
    "                })\n",
    "                print(f\"  ‚úÖ Generated embedding for {content_id}\")\n",
    "            else:\n",
    "                print(f\"  ‚ùå Failed to generate embedding for {content_id}\")\n",
    "        else:\n",
    "            print(f\"  ‚ùå Failed to generate description for {content_id}\")\n",
    "    finally:\n",
    "        # Clean up temp file\n",
    "        if os.path.exists(temp_path):\n",
    "            os.unlink(temp_path)\n",
    "\n",
    "# Summarize results\n",
    "print(\"\\nüìä Embedding generation summary:\")\n",
    "print(f\"  - Text items: {len(text_contents)}, successfully embedded: {len(text_embeddings)}\")\n",
    "print(f\"  - Image items: {len(image_contents)}, successfully embedded: {len(image_embeddings)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4a0fc05",
   "metadata": {},
   "source": [
    "## SKIP this part if you vector embedded mixed pdf with text and image\n",
    "\n",
    "### Part 3b: Use this section for TEXT only pdf or pdf with images embedded as jpg files.  This is a faster method, but it does not work for pdf with flattened images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9fda9bbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:src.embedding_manager:EmbeddingManager initialized with text model: nomic-embed-text, vision model: qwen2.5vl:3b\n",
      "INFO:src.chroma_manager:Creating new collection: sg_explorer_documents_text\n",
      "INFO:src.chroma_manager:ChromaManager initialized with collection: sg_explorer_documents_text\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Components initialized\n",
      "   - Using text embedding model: nomic-embed-text\n",
      "   - Using vision model: qwen2.5vl:3b\n",
      "   - ChromaDB persistence directory: C:\\Users\\pakke\\OneDrive - Singapore Management University\\CS605 Natural Language Processing for Smart Assistant\\Project\\RAG\\cache\\vector_db\n"
     ]
    }
   ],
   "source": [
    "'''# Initialize our embedding manager with the models we verified are working\n",
    "embedding_manager = EmbeddingManager(\n",
    "    text_embedding_model=\"nomic-embed-text\",  # Specialized embedding model\n",
    "    vision_model=\"qwen2.5vl:3b\"               # Vision model for image descriptions\n",
    ")\n",
    "\n",
    "# Initialize ChromaDB manager\n",
    "chroma_manager = ChromaManager(\n",
    "    persist_directory=VECTOR_DB_PATH,          # From config.py\n",
    "    embedding_model=\"nomic-embed-text\",        # Should match embedding_manager\n",
    "    collection_name=\"sg_explorer_documents_text\"         # Collection name for this project\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ Components initialized\")\n",
    "print(f\"   - Using text embedding model: nomic-embed-text\")\n",
    "print(f\"   - Using vision model: qwen2.5vl:3b\")\n",
    "print(f\"   - ChromaDB persistence directory: {VECTOR_DB_PATH}\")'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "64849536",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:src.document_processor:DocumentProcessor initialized with config: {'max_image_size': 1024, 'chunk_size': 1024, 'chunk_overlap': 128, 'data_dir': WindowsPath('C:/Users/pakke/OneDrive - Singapore Management University/CS605 Natural Language Processing for Smart Assistant/Project/RAG/data'), 'cache_dir': WindowsPath('C:/Users/pakke/OneDrive - Singapore Management University/CS605 Natural Language Processing for Smart Assistant/Project/RAG/cache')}\n",
      "INFO:src.document_processor:Processing singapore_explorer_guide_text1.pdf (format: pdf, size: 32595939 bytes)\n",
      "INFO:src.document_processor:Processing PDF singapore_explorer_guide_text1.pdf with 10 pages\n",
      "WARNING:src.document_processor:No text found on page 1 with any method (including OCR)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÑ Processing document: C:\\Users\\pakke\\OneDrive - Singapore Management University\\CS605 Natural Language Processing for Smart Assistant\\Project\\RAG\\data\\singapore_explorer_guide_text1.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:src.document_processor:No text found on page 2 with any method (including OCR)\n",
      "WARNING:src.document_processor:No text found on page 3 with any method (including OCR)\n",
      "WARNING:src.document_processor:No text found on page 4 with any method (including OCR)\n",
      "WARNING:src.document_processor:No text found on page 5 with any method (including OCR)\n",
      "WARNING:src.document_processor:No text found on page 6 with any method (including OCR)\n",
      "WARNING:src.document_processor:No text found on page 7 with any method (including OCR)\n",
      "WARNING:src.document_processor:No text found on page 8 with any method (including OCR)\n",
      "WARNING:src.document_processor:No text found on page 9 with any method (including OCR)\n",
      "WARNING:src.document_processor:No text found on page 10 with any method (including OCR)\n",
      "INFO:src.document_processor:PDF processing complete: 0 content pieces extracted\n",
      "INFO:src.document_processor:Successfully processed singapore_explorer_guide_text1.pdf: 0 content pieces extracted, type: unknown (confidence: 0.000)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Document processed: singapore_explorer_guide_text1.pdf\n",
      "  - Document type: unknown\n",
      "  - Page count: 10\n",
      "  - Content items: 0\n",
      "  - Text items: 0\n",
      "  - Image items: 0\n"
     ]
    }
   ],
   "source": [
    "# Process the Singapore Explorer Guide Text one at a time  \n",
    "## Takes about 1 mins to run, so please be patient.\n",
    "\n",
    "\n",
    "'''documents = [\"singapore_explorer_guide_text1.pdf\"]  # one at a time, not suitable for batch processing\n",
    "\n",
    "document_processor = DocumentProcessor()\n",
    "\n",
    "for doc in documents:\n",
    "    sg_explorer_path = DATA_DIR / doc\n",
    "    print(f\"üìÑ Processing document: {sg_explorer_path}\")\n",
    "    \n",
    "    # Process the document\n",
    "    processed_doc = document_processor.process_document(str(sg_explorer_path))\n",
    "    print(f\"‚úÖ Document processed: {processed_doc.filename}\")\n",
    "    print(f\"  - Document type: {processed_doc.document_type.value}\")\n",
    "    print(f\"  - Page count: {processed_doc.document_metadata.page_count}\")\n",
    "    print(f\"  - Content items: {len(processed_doc.extracted_contents)}\")\n",
    "    \n",
    "    # Split content by type\n",
    "    text_contents = [c for c in processed_doc.extracted_contents if c.content_type.value == 'text']\n",
    "    image_contents = [c for c in processed_doc.extracted_contents if c.content_type.value == 'image']\n",
    "    \n",
    "    print(f\"  - Text items: {len(text_contents)}\")\n",
    "    print(f\"  - Image items: {len(image_contents)}\")'''\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "cd2c4caa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# Create lists to store processed items once for each PDF\\n\\n## Takes some time to run\\n## The text_embeddings is stored in a temp file, different for each PDF. \\n## The results will be stored in the ChromaDB vector database.\\n\\n## Skip this cell if you want to query a PDF that has already been processed and stored in the vector database.\\n\\ntext_embeddings = []\\ntext_ids = []\\ntext_documents = []\\ntext_metadatas = []\\n\\n# Process text content\\nprint(\"\\nüîÑ Processing text content...\")\\nfor i, content in enumerate(text_contents):\\n    print(f\"  Processing text item {i+1}/{len(text_contents)}: {content.content_id}\")\\n    text = content.content_data\\n    content_id = content.content_id\\n    \\n    # Generate embedding\\n    embedding = embedding_manager.generate_text_embedding(text)\\n    \\n    if embedding:\\n        text_embeddings.append(embedding)\\n        text_ids.append(content_id)\\n        text_documents.append(text)\\n        text_metadatas.append({\\n            \"source\": processed_doc.filename,\\n            \"page\": content.source_page,\\n            \"content_type\": \"text\",\\n            \"document_type\": processed_doc.document_type.value\\n        })\\n        print(f\"  ‚úÖ Generated embedding for {content_id}\")\\n    else:\\n        print(f\"  ‚ùå Failed to generate embedding for {content_id}\")\\n\\n# Process image content\\nprint(\"\\nüîÑ Processing image content...\")\\nimage_embeddings = []\\nimage_ids = []\\nimage_documents = []\\nimage_metadatas = []\\n\\nimport tempfile\\nimport os\\n\\nfor i, content in enumerate(image_contents):\\n    print(f\"  Processing image item {i+1}/{len(image_contents)}: {content.content_id}\")\\n    # Save image to temp file\\n    image = content.content_data\\n    content_id = content.content_id\\n    \\n    with tempfile.NamedTemporaryFile(suffix=\".png\", delete=False) as temp_file:\\n        temp_path = temp_file.name\\n        image.save(temp_path)\\n    \\n    try:\\n        # Generate description\\n        description = embedding_manager.generate_image_description(temp_path)\\n        \\n        if description:\\n            print(f\"  ‚úì Generated description ({len(description)} chars)\")\\n            \\n            # Generate embedding for description\\n            embedding = embedding_manager.generate_text_embedding(description)\\n            \\n            if embedding:\\n                image_embeddings.append(embedding)\\n                image_ids.append(content_id)\\n                image_documents.append(description)\\n                image_metadatas.append({\\n                    \"source\": processed_doc.filename,\\n                    \"page\": content.source_page,\\n                    \"content_type\": \"image_description\",\\n                    \"document_type\": processed_doc.document_type.value\\n                })\\n                print(f\"  ‚úÖ Generated embedding for {content_id}\")\\n            else:\\n                print(f\"  ‚ùå Failed to generate embedding for {content_id}\")\\n        else:\\n            print(f\"  ‚ùå Failed to generate description for {content_id}\")\\n    finally:\\n        # Clean up temp file\\n        if os.path.exists(temp_path):\\n            os.unlink(temp_path)\\n\\n# Summarize results\\nprint(\"\\nüìä Embedding generation summary:\")\\nprint(f\"  - Text items: {len(text_contents)}, successfully embedded: {len(text_embeddings)}\")\\nprint(f\"  - Image items: {len(image_contents)}, successfully embedded: {len(image_embeddings)}\")'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''# Create lists to store processed items once for each PDF\n",
    "\n",
    "## Takes some time to run\n",
    "## The text_embeddings is stored in a temp file, different for each PDF. \n",
    "## The results will be stored in the ChromaDB vector database.\n",
    "\n",
    "## Skip this cell if you want to query a PDF that has already been processed and stored in the vector database.\n",
    "\n",
    "text_embeddings = []\n",
    "text_ids = []\n",
    "text_documents = []\n",
    "text_metadatas = []\n",
    "\n",
    "# Process text content\n",
    "print(\"\\nüîÑ Processing text content...\")\n",
    "for i, content in enumerate(text_contents):\n",
    "    print(f\"  Processing text item {i+1}/{len(text_contents)}: {content.content_id}\")\n",
    "    text = content.content_data\n",
    "    content_id = content.content_id\n",
    "    \n",
    "    # Generate embedding\n",
    "    embedding = embedding_manager.generate_text_embedding(text)\n",
    "    \n",
    "    if embedding:\n",
    "        text_embeddings.append(embedding)\n",
    "        text_ids.append(content_id)\n",
    "        text_documents.append(text)\n",
    "        text_metadatas.append({\n",
    "            \"source\": processed_doc.filename,\n",
    "            \"page\": content.source_page,\n",
    "            \"content_type\": \"text\",\n",
    "            \"document_type\": processed_doc.document_type.value\n",
    "        })\n",
    "        print(f\"  ‚úÖ Generated embedding for {content_id}\")\n",
    "    else:\n",
    "        print(f\"  ‚ùå Failed to generate embedding for {content_id}\")\n",
    "\n",
    "# Process image content\n",
    "print(\"\\nüîÑ Processing image content...\")\n",
    "image_embeddings = []\n",
    "image_ids = []\n",
    "image_documents = []\n",
    "image_metadatas = []\n",
    "\n",
    "import tempfile\n",
    "import os\n",
    "\n",
    "for i, content in enumerate(image_contents):\n",
    "    print(f\"  Processing image item {i+1}/{len(image_contents)}: {content.content_id}\")\n",
    "    # Save image to temp file\n",
    "    image = content.content_data\n",
    "    content_id = content.content_id\n",
    "    \n",
    "    with tempfile.NamedTemporaryFile(suffix=\".png\", delete=False) as temp_file:\n",
    "        temp_path = temp_file.name\n",
    "        image.save(temp_path)\n",
    "    \n",
    "    try:\n",
    "        # Generate description\n",
    "        description = embedding_manager.generate_image_description(temp_path)\n",
    "        \n",
    "        if description:\n",
    "            print(f\"  ‚úì Generated description ({len(description)} chars)\")\n",
    "            \n",
    "            # Generate embedding for description\n",
    "            embedding = embedding_manager.generate_text_embedding(description)\n",
    "            \n",
    "            if embedding:\n",
    "                image_embeddings.append(embedding)\n",
    "                image_ids.append(content_id)\n",
    "                image_documents.append(description)\n",
    "                image_metadatas.append({\n",
    "                    \"source\": processed_doc.filename,\n",
    "                    \"page\": content.source_page,\n",
    "                    \"content_type\": \"image_description\",\n",
    "                    \"document_type\": processed_doc.document_type.value\n",
    "                })\n",
    "                print(f\"  ‚úÖ Generated embedding for {content_id}\")\n",
    "            else:\n",
    "                print(f\"  ‚ùå Failed to generate embedding for {content_id}\")\n",
    "        else:\n",
    "            print(f\"  ‚ùå Failed to generate description for {content_id}\")\n",
    "    finally:\n",
    "        # Clean up temp file\n",
    "        if os.path.exists(temp_path):\n",
    "            os.unlink(temp_path)\n",
    "\n",
    "# Summarize results\n",
    "print(\"\\nüìä Embedding generation summary:\")\n",
    "print(f\"  - Text items: {len(text_contents)}, successfully embedded: {len(text_embeddings)}\")\n",
    "print(f\"  - Image items: {len(image_contents)}, successfully embedded: {len(image_embeddings)}\")'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89852f8d",
   "metadata": {},
   "source": [
    "## Part 4: Vector DB Integration "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "87ad8cc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:src.chroma_manager:Collection stats: 42 items\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîÑ Storing text embeddings in ChromaDB...\n",
      "  ‚ö†Ô∏è No text embeddings to store\n",
      "\n",
      "üîÑ Storing image embeddings in ChromaDB...\n",
      "  ‚ö†Ô∏è No image embeddings to store\n",
      "\n",
      "üìä ChromaDB collection stats:\n",
      "  - name: sg_explorer_documents\n",
      "  - count: 42\n",
      "  - embedding_model: nomic-embed-text\n",
      "  - embedding_dimension: unknown\n",
      "  - persist_directory: C:\\Users\\pakke\\OneDrive - Singapore Management University\\CS605 Natural Language Processing for Smart Assistant\\Project\\RAG\\cache\\vector_db\n"
     ]
    }
   ],
   "source": [
    "# Add text embeddings to ChromaDB.  Stores these embeddings in ChromaDB, which persists them to disk in the location specified by persist_directory (which defaults to VECTOR_DB_PATH from your config)\n",
    "\n",
    "## Skip this cell if you want to query a PDF that has already been processed and stored in the vector database.\n",
    "\n",
    "print(\"\\nüîÑ Storing text embeddings in ChromaDB...\")\n",
    "if text_embeddings:\n",
    "    \n",
    "    success = chroma_manager.add_with_embeddings(\n",
    "        texts=text_documents,\n",
    "        embeddings=text_embeddings,\n",
    "        metadatas=text_metadatas,\n",
    "        ids=text_ids\n",
    "    )\n",
    "    print(f\"  {'‚úÖ' if success else '‚ùå'} Stored {len(text_embeddings)} text embeddings\")\n",
    "else:\n",
    "    print(\"  ‚ö†Ô∏è No text embeddings to store\")\n",
    "\n",
    "# Add image embeddings to ChromaDB\n",
    "print(\"\\nüîÑ Storing image embeddings in ChromaDB...\")\n",
    "if image_embeddings:\n",
    "    success = chroma_manager.add_with_embeddings(\n",
    "        texts=image_documents,\n",
    "        embeddings=image_embeddings,\n",
    "        metadatas=image_metadatas,\n",
    "        ids=image_ids\n",
    "    )\n",
    "    print(f\"  {'‚úÖ' if success else '‚ùå'} Stored {len(image_embeddings)} image embeddings\")\n",
    "else:\n",
    "    print(\"  ‚ö†Ô∏è No image embeddings to store\")\n",
    "\n",
    "# Get collection stats\n",
    "stats = chroma_manager.get_collection_stats()\n",
    "print(f\"\\nüìä ChromaDB collection stats:\")\n",
    "for key, value in stats.items():\n",
    "    print(f\"  - {key}: {value}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "44938243",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text Embeddings: 0 0 0 0\n",
      "Image Embeddings: 0 0 0 0\n"
     ]
    }
   ],
   "source": [
    "## Make sure text_embeddings persist\n",
    "\n",
    "## Skip this cell if you want to query a PDF that has already been processed and stored in the vector database.\n",
    " \n",
    "print(\"Text Embeddings:\", len(text_embeddings), len(text_ids), len(text_documents), len(text_metadatas))\n",
    "\n",
    "print(\"Image Embeddings:\", len(image_embeddings), len(image_ids), len(image_documents), len(image_metadatas))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18cecb76",
   "metadata": {},
   "source": [
    "## Part 4b: Come straight here if you already have vector embeddings for the text and images from RAG. Begin your query by calling up vectordb from ChromaDB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "bb687400",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:src.chroma_manager:Collection stats: 42 items\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä ChromaDB collection stats:\n",
      "  - name: sg_explorer_documents\n",
      "  - count: 42\n",
      "  - embedding_model: nomic-embed-text\n",
      "  - embedding_dimension: unknown\n",
      "  - persist_directory: C:\\Users\\pakke\\OneDrive - Singapore Management University\\CS605 Natural Language Processing for Smart Assistant\\Project\\RAG\\cache\\vector_db\n",
      "\n",
      "üìÑ Sample items:\n",
      "  - IDs: ['singapore_explorer_guide_text_text_p1_000', 'singapore_explorer_guide_text_text_p2_000', 'singapore_explorer_guide_text_text_p3_000']\n",
      "  - Metadata samples: [{'document_type': 'tourism', 'page': 1, 'source': 'singapore_explorer_guide_text.pdf', 'content_type': 'text'}, {'content_type': 'text', 'source': 'singapore_explorer_guide_text.pdf', 'page': 2, 'document_type': 'tourism'}, {'page': 3, 'document_type': 'tourism', 'content_type': 'text', 'source': 'singapore_explorer_guide_text.pdf'}]\n"
     ]
    }
   ],
   "source": [
    "# If PDF vector embeddings already stored in Chroma DB, get stats directly about your collection\n",
    "\n",
    "## If you want to query a PDF that has already been processed and stored in the vector database, start from here.\n",
    "stats = chroma_manager.get_collection_stats()\n",
    "print(f\"üìä ChromaDB collection stats:\")\n",
    "for key, value in stats.items():\n",
    "    print(f\"  - {key}: {value}\")\n",
    "\n",
    "# Peek at some items in the collection\n",
    "sample = chroma_manager.collection.peek(limit=3)\n",
    "print(f\"\\nüìÑ Sample items:\")\n",
    "print(f\"  - IDs: {sample['ids']}\")\n",
    "print(f\"  - Metadata samples: {sample['metadatas'][:3]}\")  # Show first 3 metadata entries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b75bbf2b",
   "metadata": {},
   "source": [
    "## Part 5: Generate RAG Query for Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2161d493",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:src.rag_query:RAGQueryEngine initialized with default_results=3\n",
      "INFO:src.rag_query:Query: What is the purpose of this document? Please summarise in no more than 100 words.\n",
      "INFO:src.chroma_manager:Embedding query returned 3 results\n",
      "INFO:src.rag_query:Found 3 relevant chunks\n",
      "INFO:src.rag_query:Result 1: Relevance: -365.1010, Source: mixed_singapore_explorer_guide_text1, Page: 5, Type: image_description\n",
      "INFO:src.rag_query:Content preview: The image appears to be a promotional or informational page for a museum or educational center in Si...\n",
      "INFO:src.rag_query:Result 2: Relevance: -382.9700, Source: mixed_singapore_explorer_guide_text1, Page: 1, Type: image_description\n",
      "INFO:src.rag_query:Content preview: The image is a simple, clean design with a predominantly red background. At the top right corner, th...\n",
      "INFO:src.rag_query:Result 3: Relevance: -383.4837, Source: mixed_singapore_explorer_guide_text1, Page: 9, Type: image_description\n",
      "INFO:src.rag_query:Content preview: The image is a promotional page for scenic trails in Singapore, specifically designed for running, h...\n",
      "INFO:src.rag_query:Answer: The purpose of this document is to provide information about various trails in Singapore, specifically designed for running, hiking, and biking. The document is divided into several sections, each featuring different trails and their respective descriptions. The design is clean and visually appealing, with high-quality images that help convey the scenic and recreational aspects of the trails. The text is clear and concise, providing a brief description of each trail and its location.\n"
     ]
    }
   ],
   "source": [
    "# Generate Rag Query  \n",
    "from src.rag_query import RAGQueryEngine\n",
    "\n",
    "# Initialize the RAG query engine\n",
    "rag_engine = RAGQueryEngine(\n",
    "    embedding_manager=embedding_manager,\n",
    "    chroma_manager=chroma_manager,\n",
    "    ollama_manager=ollama_manager,\n",
    "    default_results=3\n",
    ")\n",
    "\n",
    "# Now you can use it to perform queries\n",
    "result = rag_engine.query(\"What is the purpose of this document? Please summarise in no more than 100 words.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0c177a2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:src.rag_query:Query: You are a personal travel agent.  Your client is looking for a travel itinerary for a four day trip to Singapore.  Your client has a family of two adults and two children, and is interested in food and culture activities at night for the adults and scientific exploration for the children during the day. Please generate a four day itinerary for your client with half a rest day on Day 2.\n",
      "INFO:src.chroma_manager:Embedding query returned 3 results\n",
      "INFO:src.rag_query:Found 3 relevant chunks\n",
      "INFO:src.rag_query:Result 1: Relevance: -219.2856, Source: singapore_explorer_guide_image.pdf, Page: 9, Type: text\n",
      "INFO:src.rag_query:Content preview: ACTIVITIES TO\n",
      "EXPLORE IN SINGAPORE\n",
      "\n",
      "BOX BACKPACKERS HOSTEL\n",
      "\n",
      "1 VESPA TOURS BY BETEL\n",
      "& TOURS AND SIDEW...\n",
      "INFO:src.rag_query:Result 2: Relevance: -220.2726, Source: singapore_explorer_guide_text.pdf, Page: 9, Type: text\n",
      "INFO:src.rag_query:Content preview: / 09 - ACTIVITIES TO EXPLORE IN SINGAPORE /\n",
      "\n",
      "If you need company while exploring\n",
      "\n",
      "ACTIVITIES TO Shge...\n",
      "INFO:src.rag_query:Result 3: Relevance: -220.2726, Source: mixed_singapore_explorer_guide_text1, Page: 8, Type: text\n",
      "INFO:src.rag_query:Content preview: / 09 - ACTIVITIES TO EXPLORE IN SINGAPORE /\n",
      "\n",
      "If you need company while exploring\n",
      "\n",
      "ACTIVITIES TO Shge...\n",
      "INFO:src.rag_query:Answer: Day 1: \n",
      "- Start the day with a visit to the National Parks Board's Central Nature Reserve, where the children can learn about the local flora and fauna.\n",
      "- In the afternoon, take a Vespa tour through Chinatown and Joo Chiat, where the adults can enjoy a food and pub trail and the children can explore the traditional customs of the early Chinese immigrants.\n",
      "- In the evening, take a leisure Trishaw Ride down to Clarke Quay and hop onto a Bumboat Cruise along Singapore River, where the adults can enjoy authentic Chinese food and the children can test their bargaining skills.\n",
      "\n",
      "Day 2: \n",
      "- Rest day. The adults can enjoy a leisurely breakfast at a local coffee shop and the children can explore the Singapore River and the Singapore River Park.\n",
      "\n",
      "Day 3: \n",
      "- In the morning, take a guided walk through the Singapore River Park and the Singapore River, where the adults can learn about the history and culture of Singapore and the children can explore the various attractions along the river.\n",
      "- In the afternoon, take a Vespa tour through Little India and Kampong Glam, where the adults can enjoy a food and pub trail and the children can explore the traditional customs of the early Indian immigrants.\n",
      "- In the evening, take a leisure Trishaw Ride down to Clarke Quay and hop onto a Bumboat Cruise along Singapore River, where the adults can enjoy authentic Chinese food and the children can test their bargaining skills.\n",
      "\n",
      "Day 4: \n",
      "- In the morning, take a guided walk through the Singapore River Park and the Singapore River, where the adults can learn about the history and culture of Singapore and the children can explore the various attractions along the river.\n",
      "- In the afternoon, take a guided walk through the Singapore Botanic Gardens, where the adults can learn about the local flora and fauna and the children can explore the various attractions and learn about the scientific exploration of the Singapore Botanic Gardens.\n",
      "- In the evening, take a leisure Trishaw Ride down to Clarke Quay and hop onto a Bumboat Cruise along Singapore River, where the adults can enjoy authentic Chinese food and the children can test their bargaining skills.\n"
     ]
    }
   ],
   "source": [
    "# Takes about 2 mins to generate\n",
    "result1 = rag_engine.query(\"You are a personal travel agent.  Your client is looking for a travel itinerary for a four day trip to Singapore.  Your client has a family of two adults and two children, and is interested in food and culture activities at night for the adults and scientific exploration for the children during the day. Please generate a four day itinerary for your client with half a rest day on Day 2.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6bf0fd7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:src.rag_query:Query: You are a personal travel agent.  Your client is looking for a travel itinerary for six day trip to Singapore.  Your client is an active couple with no children, and is interested in outdoor and cultural activities during the day and good food for dinner at night followed by a trip to the bar or club.  Please generate a six day itinerary for your client with a rest day on Day 3.\n",
      "INFO:src.chroma_manager:Embedding query returned 3 results\n",
      "INFO:src.rag_query:Found 3 relevant chunks\n",
      "INFO:src.rag_query:Result 1: Relevance: -216.5031, Source: singapore_explorer_guide_image.pdf, Page: 9, Type: text\n",
      "INFO:src.rag_query:Content preview: ACTIVITIES TO\n",
      "EXPLORE IN SINGAPORE\n",
      "\n",
      "BOX BACKPACKERS HOSTEL\n",
      "\n",
      "1 VESPA TOURS BY BETEL\n",
      "& TOURS AND SIDEW...\n",
      "INFO:src.rag_query:Result 2: Relevance: -224.7441, Source: singapore_explorer_guide_text.pdf, Page: 9, Type: text\n",
      "INFO:src.rag_query:Content preview: / 09 - ACTIVITIES TO EXPLORE IN SINGAPORE /\n",
      "\n",
      "If you need company while exploring\n",
      "\n",
      "ACTIVITIES TO Shge...\n",
      "INFO:src.rag_query:Result 3: Relevance: -224.7441, Source: mixed_singapore_explorer_guide_text1, Page: 8, Type: text\n",
      "INFO:src.rag_query:Content preview: / 09 - ACTIVITIES TO EXPLORE IN SINGAPORE /\n",
      "\n",
      "If you need company while exploring\n",
      "\n",
      "ACTIVITIES TO Shge...\n",
      "INFO:src.rag_query:Answer: Day 1: Explore Singapore's cultural heritage and history through a Vespa tour, followed by a visit to the National Parks Board's guided walks in the parks and gardens. Enjoy a delicious dinner at a local restaurant and end the day with a night out at a bar or club.\n",
      "\n",
      "Day 2: Take a leisurely trishaw ride through the vibrant streets of Singapore, visiting Little India, Kampong Glam, and Chinatown. Enjoy a delicious dinner at a local restaurant and end the day with a night out at a bar or club.\n",
      "\n",
      "Day 3: Rest day. Enjoy a leisurely breakfast at a local caf√© and spend the day relaxing at a beach or pool. Enjoy a delicious dinner at a local restaurant and end the day with a night out at a bar or club.\n",
      "\n",
      "Day 4: Take a guided walk along the Singapore River, visiting historical landmarks and museums. Enjoy a delicious dinner at a local restaurant and end the day with a night out at a bar or club.\n",
      "\n",
      "Day 5: Take a Vespa tour through the heritage lanes of Chinatown and Joo Chiat, followed by a visit to the Chinatown Association's walking tour. Enjoy a delicious dinner at a local restaurant and end the day with a night out at a bar or club.\n",
      "\n",
      "Day 6: Take a guided walk through the National Parks Board's parks and gardens, followed by a visit to the Botanic Gardens. Enjoy a delicious dinner at a local restaurant and end the day with a night out at a bar or club.\n"
     ]
    }
   ],
   "source": [
    "# takes about 2 mins to generate\n",
    "result2 = rag_engine.query(\"You are a personal travel agent.  Your client is looking for a travel itinerary for six day trip to Singapore.  Your client is an active couple with no children, and is interested in outdoor and cultural activities during the day and good food for dinner at night followed by a trip to the bar or club.  Please generate a six day itinerary for your client with a rest day on Day 3.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d205283",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the text Query-Answer-Pairs using RAG results manager\n",
    "\n",
    "from src.rag_results_manager import RAGResultsManager\n",
    "\n",
    "# Initialize the manager\n",
    "results_manager = RAGResultsManager()\n",
    "\n",
    "# Add your existing results\n",
    "results_manager.add_result(result, \"query0\")\n",
    "results_manager.add_result(result1, \"query1\")\n",
    "results_manager.add_result(result2, \"query2\")\n",
    "\n",
    "# Display a single result\n",
    "results_manager.display_result(result1)\n",
    "\n",
    "# Display a summary table in Markdown format\n",
    "results_manager.display_markdown_table()\n",
    "\n",
    "# Or display a formatted HTML table\n",
    "results_manager.display_summary_table()\n",
    "\n",
    "# Save results to a file\n",
    "output_file = results_manager.save_results(\"singapore_explorer_text1_QAP.json\")\n",
    "print(f\"Results saved to: {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a9cd54b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# takes about 2 mins to generate\n",
    "result3 = rag_engine.query(\"You are a personal travel agent.  Your client has a family of 4 with two children aged 6 and 9 visiting Singapore for 5 days. They love interactive science exhibits, nature parks, and kid-friendly activities. Please generate an itinerary with one rest day in the middle.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f1ed092",
   "metadata": {},
   "outputs": [],
   "source": [
    "# takes about 2 mins to generate\n",
    "result4 = rag_engine.query(\"You are a personal travel agent.  Your client a couple, husband and wife (both 65+), are visiting Singapore for 4 days. They're interested in heritage sites, museums, and cultural districts like Chinatown and Little India. Please generate an itinerary with one relaxing day to rest in the middle.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c18cf190",
   "metadata": {},
   "outputs": [],
   "source": [
    "# takes about 2 mins to generate\n",
    "result5 = rag_engine.query(\"You are a personal travel agent.  Your clients are 6 young adults (25-30) staying in Singapore for 6 days. They love outdoor activities, hiking trails, cycling, and unique experiences like night safaris. Please generate an itinerary with one relaxing day to rest in the middle.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22402b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the text Query-Answer-Pairs using RAG results manager\n",
    "\n",
    "from src.rag_results_manager import RAGResultsManager\n",
    "\n",
    "# Initialize the manager\n",
    "results_manager = RAGResultsManager()\n",
    "\n",
    "# Add your existing results\n",
    "results_manager.add_result(result3, \"query3\")\n",
    "results_manager.add_result(result4, \"query4\")\n",
    "results_manager.add_result(result5, \"query5\")\n",
    "\n",
    "# Display a summary table in Markdown format\n",
    "results_manager.display_markdown_table()\n",
    "\n",
    "# Or display a formatted HTML table\n",
    "results_manager.display_summary_table()\n",
    "\n",
    "# Save results to a file\n",
    "output_file = results_manager.save_results(\"singapore_explorer_text2_QAP.json\")\n",
    "print(f\"Results saved to: {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4d38878",
   "metadata": {},
   "outputs": [],
   "source": [
    "# takes about 2 mins to generate\n",
    "result6 = rag_engine.query(\"You are a personal travel agent.  Your clients are three colleagues extending their business trip for a 3-day Singapore weekend. They want efficient sightseeing covering major landmarks, Gardens by the Bay, and Marina Bay area. Please generate an itinerary with one lighter day for recovery.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8888d1be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# takes about 2 mins to generate\n",
    "result7 = rag_engine.query(\"You are a personal travel agent.  Your clients are a group of 8 spanning three generations (grandparents, parents, teens) visiting for 7 days. They need activities suitable for all ages including accessible attractions, traditional food experiences, and family-friendly entertainment. Please generate an itinerary with one rest day for recovery.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41504855",
   "metadata": {},
   "outputs": [],
   "source": [
    "# takes about 2 mins to generate\n",
    "result8 = rag_engine.query(\"You are a personal travel agent.  Your clients are two couples (in their 40s) on a 4-day culinary and cultural journey. They are interested in hawker centers, cultural heritage, cooking experiences, and traditional markets. Please generate an itinerary with one lighter day for recovery.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d341e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the text Query-Answer-Pairs using RAG results manager\n",
    "\n",
    "from src.rag_results_manager import RAGResultsManager\n",
    "\n",
    "# Initialize the manager\n",
    "results_manager = RAGResultsManager()\n",
    "\n",
    "# Add your existing results\n",
    "results_manager.add_result(result6, \"query6\")\n",
    "results_manager.add_result(result7, \"query7\")\n",
    "results_manager.add_result(result8, \"query8\")\n",
    "\n",
    "# Display a summary table in Markdown format\n",
    "results_manager.display_markdown_table()\n",
    "\n",
    "# Or display a formatted HTML table\n",
    "results_manager.display_summary_table()\n",
    "\n",
    "# Save results to a file\n",
    "output_file = results_manager.save_results(\"singapore_explorer_text3_QAP.json\")\n",
    "print(f\"Results saved to: {output_file}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5a7c0a9",
   "metadata": {},
   "source": [
    "## Part 6: Generate RAG Query for Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac33bd4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need both the Text Query and the Image Query Engines\n",
    "\n",
    "# Create an actual instance of DocumentProcessor\n",
    "from src.document_processor import DocumentProcessor\n",
    "document_processor = DocumentProcessor()  # This creates an instance\n",
    "\n",
    "import importlib\n",
    "import src.rag_query\n",
    "from src.rag_query import RAGQueryEngine\n",
    "\n",
    "# Initialize the Text Query Engine with the document_processor instance\n",
    "rag_engine = RAGQueryEngine(\n",
    "    embedding_manager=embedding_manager,\n",
    "    chroma_manager=chroma_manager,\n",
    "    ollama_manager=ollama_manager,\n",
    "    document_processor=document_processor,  # Pass the actual instance\n",
    "    default_results=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8814f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the ImageQueryHelper, instantiate an instance of the class\n",
    "\n",
    "from src.image_query import ImageQueryHelper\n",
    "\n",
    "# Initialize the image query helper\n",
    "image_helper = ImageQueryHelper(\n",
    "    rag_engine=rag_engine,\n",
    "    chroma_manager=chroma_manager,\n",
    "    embedding_manager=embedding_manager\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "761f1246",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the ImageResultsManager,  instantiate an instance of the class\n",
    "\n",
    "from src.image_results_manager import ImageResultsManager\n",
    "\n",
    "# Now create the manager with updated code\n",
    "image_results_manager = ImageResultsManager()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ec29794",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query ChromaDB directly with page filter\n",
    "results = chroma_manager.query(\n",
    "    query_text=\"tourist attractions\",\n",
    "    n_results=3,\n",
    "    where={\"page\": 3}  # Filter to page 3 only\n",
    ")\n",
    "# Then format for display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd81a327",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary to store image query results\n",
    "## This is an image query that returns and displays images \n",
    "## May take more than 12 mins to run\n",
    "\n",
    "image_result_dict = {}\n",
    "\n",
    "# Example 1: Find general images for photography\n",
    "print(\"\\n=== Finding Photographer images related to Singapore Tourism ===\")\n",
    "image_result1 = image_helper.find_images_by_query(\"Four photography hobbyists want the most photogenic locations - architecture, nature, street scenes, and cultural sites. Show the top three images of scenic spots and sites.\", n_results=3)\n",
    "image_helper.display_image_results(image_result1)  \n",
    "image_result_dict['singapore_photography_sights_query'] = image_result1\n",
    "\n",
    "# Example 2: Find nature and garden images \n",
    "print(\"\\n=== Finding nature and garden images ===\")\n",
    "image_result2 = image_helper.find_images_by_query(\"A couple passionate about botany and wildlife want to explore Singapore Botanic Garden, nature reserves, bird watching spots, and conservation areas. Show three images of nature attractions and gardens\", n_results=3)\n",
    "image_helper.display_image_results(image_result2)  \n",
    "image_result_dict['singapore_nature_gardens_query'] = image_result2\n",
    "\n",
    "# Example 3: Find by art and creative attractions \n",
    "print(\"\\n=== Finding art and creative attractions ===\")\n",
    "image_result3 = image_helper.find_images_by_query(\"Three art teachers visiting Singapore are interested in National Gallery, contemporary art spaces, creative districts, and hands-on art experiences. Show three images of art venues and creative attractions.\", n_results=3)\n",
    "image_helper.display_image_results(image_result3)  \n",
    "image_result_dict['singapore_art_creative_query'] = image_result3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "012f577f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(image_result_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c52c8de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# See all source files in your collection\n",
    "for result in image_result1['results']:\n",
    "    print(f\"Stored as: {result['source_file']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76191eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Display summary of all results\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"=== COMPREHENSIVE RESULTS SUMMARY ===\")\n",
    "print(\"=\"*100)\n",
    "image_helper.display_image_result_dict(image_result_dict)\n",
    "\n",
    "# Add results to manager and save - SIMPLE VERSION\n",
    "print(\"\\n=== SAVING RESULTS ===\")\n",
    "image_results_manager.add_results(image_result_dict)\n",
    "\n",
    "# Save results to a file\n",
    "output_file = image_results_manager.save_results(\"singapore_explorer_image2_QAP.json\")\n",
    "print(f\"Results saved to: {output_file}\")\n",
    "\n",
    "# Optional: Show summary\n",
    "summary = image_results_manager.get_results_summary()\n",
    "print(f\"Summary: {summary}\")\n",
    "\n",
    "# Optional: List all saved files\n",
    "saved_files = image_results_manager.list_saved_files()\n",
    "print(f\"Available files: {saved_files}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "923ec359",
   "metadata": {},
   "source": [
    "## Part 7: generate text answers to a text query of image.  It returns text descriptions of the images being queried, but no image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e23d1107",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_results = image_helper.find_images_by_query(\"Gardens by the Bay\", n_results=3)\n",
    "print(\"Results found:\")\n",
    "for i, result in enumerate(image_results['results']):\n",
    "    print(f\"  {i+1}. Source: {result['source_file']}, Page: {result['page']}\")\n",
    "    print(f\"     Description: {result['description'][:200]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f6c9314",
   "metadata": {},
   "outputs": [],
   "source": [
    "## There is room for improvement through prompt engineering.  General enquiries where the OCR has not read text similar to prompt will return very generic responses. Specific queries can return more detailed responses. \n",
    "\n",
    "## Page numbers where images are being queried cannot be specified because image search stores vector embeddings of image without page numbers. \n",
    "\n",
    "## Several images on one page can only be \"parsed\" manually by hand if User only wants to return that image and not the whole page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cd6072a",
   "metadata": {},
   "outputs": [],
   "source": [
    "whos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ccae10",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d273422",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f6ef888",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eb5c07b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91667450",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55d6e9ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1842bc7b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a11fb31d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1df73d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88e11d90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d2e79ea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (NLP)",
   "language": "python",
   "name": "nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
